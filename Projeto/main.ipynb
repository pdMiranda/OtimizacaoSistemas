{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830caf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "N_WEIGHTS = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Carregando dados\")\n",
    "data = np.loadtxt('./data/wine.data', delimiter=',')\n",
    "\n",
    "X, y = data[:, 1:], data[:,0]\n",
    "\n",
    "# Transforma em problema de classificação binária\n",
    "idxs = [i for i in range(len(y)) if y[i] == 1 or y[i] == 2]\n",
    "X, y = X[idxs], y[idxs]\n",
    "\n",
    "# Normaliza os dados\n",
    "X = (X - X.mean(axis=0))/(X.max(axis=0) - X.min(axis=0))\n",
    "X = np.hstack((X, np.ones(len(X)).reshape(len(X),1)))\n",
    "# Transforma variável target\n",
    "y = np.array(list(map(lambda x: 0 if x == 1 else 1, y)))\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} amostras, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTreinando modelo benchmark (Scikit-Learn)\")\n",
    "reg = LogisticRegression(solver='sag', C=100000, max_iter=10000).fit(X, y)\n",
    "L_star = log_loss(y, reg.predict_proba(X))\n",
    "print(f\"Loss L* (benchmark) = {L_star:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4777d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def cross_entropy_loss(y, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -(1/len(y))*np.sum(y*np.log(y_pred) + (1 - y)*np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "def cross_entropy_grad(y, y_pred, X):\n",
    "    return list(np.dot((y_pred - y), X)[0])\n",
    "\n",
    "def compute_loss_for_weights(w, X, y):\n",
    "    \"\"\"Calcula loss para um dado conjunto de pesos\"\"\"\n",
    "    y_pred = sigmoid(np.dot(w.T, X.T))\n",
    "    return cross_entropy_loss(y, y_pred)\n",
    "\n",
    "def train_coordinate_descent(X_train, y_train, num_weights, eta=0.01, patience=1000, \n",
    "                             min_improvement=1e-6, max_iter=1000000, desc=\"\"):\n",
    "    \"\"\"Treinar com descida coordenada\"\"\"\n",
    "    w = np.zeros(num_weights).reshape(num_weights, 1)\n",
    "    loss_history = []\n",
    "    weights_history = []\n",
    "    best_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(desc=desc, total=max_iter)\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        y_pred = sigmoid(np.dot(w.T, X_train.T))\n",
    "        current_loss = cross_entropy_loss(y_train, y_pred)\n",
    "        loss_history.append(current_loss)\n",
    "        \n",
    "        grad = list(np.dot((y_pred - y_train), X_train)[0])\n",
    "        grad_abs = [abs(g) for g in grad]\n",
    "        best_index = grad_abs.index(max(grad_abs))\n",
    "        \n",
    "        w[best_index] = w[best_index] - eta*grad[best_index]\n",
    "        weights_history.append(w.flatten().copy())\n",
    "        \n",
    "        if current_loss < best_loss - min_improvement:\n",
    "            best_loss = current_loss\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "        \n",
    "        if no_improvement_count >= patience:\n",
    "            print(f\"\\nConvergencia atingida na iteracao {t}\")\n",
    "            pbar.close()\n",
    "            break\n",
    "        \n",
    "        pbar.update(1)\n",
    "        if t == max_iter - 1:\n",
    "            print(f\"\\nMaximo de iteracoes ({max_iter}) atingido\")\n",
    "            pbar.close()\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    weights_history = np.array(weights_history)\n",
    "    \n",
    "    y_pred = sigmoid(np.dot(w.T, X_train.T))\n",
    "    y_pred_class = np.array(list(map(lambda x: 1 if x >= 0.5 else 0, y_pred.flatten())))\n",
    "    accuracy = accuracy_score(y_train, y_pred_class)\n",
    "    \n",
    "    return {\n",
    "        'weights': w,\n",
    "        'loss_history': loss_history,\n",
    "        'weights_history': weights_history,\n",
    "        'time': training_time,\n",
    "        'iterations': len(loss_history),\n",
    "        'accuracy': accuracy,\n",
    "        'final_loss': loss_history[-1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c509263",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gradient = np.zeros(14).reshape(14, 1)\n",
    "eta = 0.05\n",
    "num_features = 14\n",
    "patience = 1000\n",
    "min_improvement = 1e-6\n",
    "max_iter = 1000000\n",
    "\n",
    "loss_gradient = []\n",
    "weights_history_gradient = []\n",
    "gradient_selections = np.zeros(num_features)\n",
    "iteration_log = []\n",
    "\n",
    "best_loss = float('inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "start_time = time.time()\n",
    "pbar = tqdm(desc=\"Descida com Gradiente (14 pesos)\", total=max_iter)\n",
    "\n",
    "for t in range(max_iter):\n",
    "    y_pred = sigmoid(np.dot(w_gradient.T, X.T))\n",
    "    current_loss = cross_entropy_loss(y, y_pred)\n",
    "    loss_gradient.append(current_loss)\n",
    "    \n",
    "    grad = cross_entropy_grad(y, y_pred, X)\n",
    "    grad_abs = [abs(g) for g in grad]\n",
    "    best_index = grad_abs.index(max(grad_abs))\n",
    "    gradient_selections[best_index] += 1\n",
    "    \n",
    "    w_gradient[best_index] = w_gradient[best_index] - eta*grad[best_index]\n",
    "    weights_history_gradient.append(w_gradient.flatten().copy())\n",
    "    \n",
    "    if t % 1000 == 0 or t < 10:\n",
    "        iteration_log.append({\n",
    "            'Iteracao': t,\n",
    "            'Loss': current_loss,\n",
    "            'Melhor Indice': best_index,\n",
    "            'Gradiente Max': max(grad_abs),\n",
    "            'Delta Loss': current_loss - best_loss if t > 0 else 0\n",
    "        })\n",
    "    \n",
    "    if current_loss < best_loss - min_improvement:\n",
    "        best_loss = current_loss\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "    \n",
    "    if no_improvement_count >= patience:\n",
    "        print(f\"\\nConvergencia atingida na iteracao {t}\")\n",
    "        pbar.close()\n",
    "        break\n",
    "    \n",
    "    pbar.update(1)\n",
    "    if t == max_iter - 1:\n",
    "        print(f\"\\nMaximo de iteracoes ({max_iter}) atingido\")\n",
    "        pbar.close()\n",
    "\n",
    "time_gradient = time.time() - start_time\n",
    "weights_history_gradient = np.array(weights_history_gradient)\n",
    "total_iterations_14 = len(loss_gradient)\n",
    "\n",
    "y_pred_gradient = sigmoid(np.dot(w_gradient.T, X.T))\n",
    "y_pred_gradient_class = np.array(list(map(lambda x: 1 if x >= 0.5 else 0, y_pred_gradient.flatten())))\n",
    "\n",
    "print(f\"\\nResultados:\")\n",
    "print(f\"  Tempo de execucao: {time_gradient:.2f}s\")\n",
    "print(f\"  Total de iteracoes: {total_iterations_14:,}\")\n",
    "print(f\"  Loss final: {loss_gradient[-1]:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83303b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_normalized = gradient_selections / gradient_selections.sum()\n",
    "weight_magnitude = np.abs(w_gradient.flatten())\n",
    "magnitude_normalized = weight_magnitude / weight_magnitude.sum()\n",
    "weight_variance = np.var(weights_history_gradient, axis=0)\n",
    "variance_normalized = weight_variance / weight_variance.sum()\n",
    "importance_score = (freq_normalized + magnitude_normalized + variance_normalized) / 3\n",
    "\n",
    "# Seleciona os top N e top 2 pesos\n",
    "top_n_indices = np.argsort(importance_score)[-N_WEIGHTS:][::-1]\n",
    "top_2_indices = np.argsort(importance_score)[-2:][::-1]\n",
    "\n",
    "print(f\"\\nTOP {N_WEIGHTS} PESOS MAIS IMPORTANTES:\")\n",
    "for rank, idx in enumerate(top_n_indices, 1):\n",
    "    print(f\"#{rank} - w_{idx}: score = {importance_score[idx]:.6f}\")\n",
    "\n",
    "print(f\"\\nTOP 2 PESOS MAIS IMPORTANTES:\")\n",
    "for rank, idx in enumerate(top_2_indices, 1):\n",
    "    print(f\"#{rank} - w_{idx}: score = {importance_score[idx]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 13 in top_n_indices:\n",
    "    X_n_weights = X[:, top_n_indices]\n",
    "    feature_indices_n = top_n_indices\n",
    "    print(f\"Dataset: features {list(top_n_indices)} (inclui bias)\")\n",
    "else:\n",
    "    feature_indices_n = list(top_n_indices) + [13]\n",
    "    X_n_weights = X[:, feature_indices_n]\n",
    "    print(f\"Dataset: features {list(top_n_indices)} + bias (w_13)\")\n",
    "\n",
    "results_n = train_coordinate_descent(\n",
    "    X_n_weights, y, len(feature_indices_n), eta, patience, min_improvement, max_iter,\n",
    "    f\"Descida com Gradiente ({len(feature_indices_n)} pesos)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nResultados:\")\n",
    "print(f\"  Tempo de execucao: {results_n['time']:.2f}s\")\n",
    "print(f\"  Total de iteracoes: {results_n['iterations']:,}\")\n",
    "print(f\"  Loss final: {results_n['final_loss']:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14937bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 13 in top_2_indices:\n",
    "    X_2_weights = X[:, top_2_indices]\n",
    "    feature_indices_2 = top_2_indices\n",
    "    print(f\"Dataset: features {list(top_2_indices)} (inclui bias)\")\n",
    "else:\n",
    "    feature_indices_2 = list(top_2_indices) + [13]\n",
    "    X_2_weights = X[:, feature_indices_2]\n",
    "    print(f\"Dataset: features {list(top_2_indices)} + bias (w_13)\")\n",
    "\n",
    "results_2 = train_coordinate_descent(\n",
    "    X_2_weights, y, len(feature_indices_2), eta, patience, min_improvement, max_iter,\n",
    "    f\"Descida com Gradiente ({len(feature_indices_2)} pesos)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nResultados:\")\n",
    "print(f\"  Tempo de execucao: {results_2['time']:.2f}s\")\n",
    "print(f\"  Total de iteracoes: {results_2['iterations']:,}\")\n",
    "print(f\"  Loss final: {results_2['final_loss']:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCOMPARACAO DE LOSS:\")\n",
    "print(f\"  Benchmark (Scikit-Learn):              {L_star:.10f}\")\n",
    "print(f\"  Versao 1 (14 pesos):                   {loss_gradient[-1]:.10f}  (diff: +{loss_gradient[-1] - L_star:.10f})\")\n",
    "print(f\"  Versao 2 ({len(feature_indices_n)} pesos):                    {results_n['final_loss']:.10f}  (diff: +{results_n['final_loss'] - L_star:.10f})\")\n",
    "print(f\"  Versao 3 ({len(feature_indices_2)} pesos):                    {results_2['final_loss']:.10f}  (diff: +{results_2['final_loss'] - L_star:.10f})\")\n",
    "\n",
    "print(\"\\nCOMPARACAO DE TEMPO:\")\n",
    "print(f\"  Versao 1 (14 pesos):     {time_gradient:.2f}s  ({total_iterations_14:,} iteracoes)\")\n",
    "print(f\"  Versao 2 ({len(feature_indices_n)} pesos):      {results_n['time']:.2f}s  ({results_n['iterations']:,} iteracoes) - speedup: {time_gradient/results_n['time']:.2f}x\")\n",
    "print(f\"  Versao 3 ({len(feature_indices_2)} pesos):      {results_2['time']:.2f}s  ({results_2['iterations']:,} iteracoes) - speedup: {time_gradient/results_2['time']:.2f}x\")\n",
    "\n",
    "# Calculos de degradacao\n",
    "deg_n = ((results_n['final_loss'] - loss_gradient[-1])/loss_gradient[-1]*100)\n",
    "deg_2 = ((results_2['final_loss'] - loss_gradient[-1])/loss_gradient[-1]*100)\n",
    "speedup_n = ((time_gradient - results_n['time'])/time_gradient*100)\n",
    "speedup_2 = ((time_gradient - results_2['time'])/time_gradient*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparacao de Loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(loss_gradient, 'r-', label=f'Versao 1 (14 pesos)', alpha=0.7, linewidth=1.5)\n",
    "plt.plot(results_n['loss_history'], 'b-', label=f'Versao 2 ({len(feature_indices_n)} pesos)', alpha=0.7, linewidth=1.5)\n",
    "plt.plot(results_2['loss_history'], 'g-', label=f'Versao 3 ({len(feature_indices_2)} pesos)', alpha=0.7, linewidth=1.5)\n",
    "plt.axhline(y=L_star, color='orange', linestyle='--', linewidth=2, label='L* (Benchmark)')\n",
    "plt.title('Comparacao: Iteracao vs Loss', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Iteracao', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "max_iter_plot = max(total_iterations_14, results_n['iterations'], results_2['iterations'])\n",
    "plt.xlim(0, max_iter_plot)\n",
    "plt.ylim(-0.01, 0.15)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evolucao dos 14 pesos\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 16))\n",
    "fig.suptitle('Evolucao de Cada Peso - Descida Coordenada (14 pesos)', \n",
    "             fontsize=24, fontweight='bold')\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for i in range(num_features):\n",
    "    ax = axes_flat[i]\n",
    "    if i in top_2_indices:\n",
    "        color, linewidth, label_suffix = 'red', 2.5, ' (TOP 2)'\n",
    "    elif i in top_n_indices:\n",
    "        color, linewidth, label_suffix = 'orange', 2.0, f' (TOP {N_WEIGHTS})'\n",
    "    else:\n",
    "        color, linewidth, label_suffix = 'steelblue', 1.0, ''\n",
    "    \n",
    "    ax.plot(weights_history_gradient[:, i], color=color, linewidth=linewidth)\n",
    "    ax.set_title(f'Peso w_{i}{label_suffix}', fontsize=12, \n",
    "                fontweight='bold' if label_suffix else 'normal')\n",
    "    ax.set_xlabel('Iteracao', fontsize=10)\n",
    "    ax.set_ylabel('Valor', fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "axes_flat[14].axis('off')\n",
    "axes_flat[15].axis('off')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Grafico de barras: Importancia\n",
    "plt.figure(figsize=(14, 6))\n",
    "x_pos = np.arange(num_features)\n",
    "colors = []\n",
    "for i in range(num_features):\n",
    "    if i in top_2_indices:\n",
    "        colors.append('red')\n",
    "    elif i in top_n_indices:\n",
    "        colors.append('orange')\n",
    "    else:\n",
    "        colors.append('steelblue')\n",
    "\n",
    "bars = plt.bar(x_pos, importance_score, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "plt.xlabel('Indice do Peso', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Score de Importancia', fontsize=14, fontweight='bold')\n",
    "plt.title('Importancia dos Pesos (Score Combinado)', fontsize=18, fontweight='bold')\n",
    "plt.xticks(x_pos, [f'w_{i}' for i in range(num_features)])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (idx, score) in enumerate(zip(x_pos, importance_score)):\n",
    "    if idx in top_2_indices:\n",
    "        plt.text(i, score + 0.005, 'TOP 2', ha='center', fontsize=9, fontweight='bold')\n",
    "    elif idx in top_n_indices:\n",
    "        plt.text(i, score + 0.005, f'TOP {N_WEIGHTS}', ha='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizacao 3D - Apenas para versao com 2 pesos\n",
    "print(\"\\nCalculando espaco de solucoes para versao com 2 pesos\")\n",
    "\n",
    "w0_min, w0_max = results_2['weights_history'][:, 0].min(), results_2['weights_history'][:, 0].max()\n",
    "w1_min, w1_max = results_2['weights_history'][:, 1].min(), results_2['weights_history'][:, 1].max()\n",
    "\n",
    "w0_margin = (w0_max - w0_min) * 0.5\n",
    "w1_margin = (w1_max - w1_min) * 0.5\n",
    "\n",
    "w0_range = np.linspace(w0_min - w0_margin, w0_max + w0_margin, 100)\n",
    "w1_range = np.linspace(w1_min - w1_margin, w1_max + w1_margin, 100)\n",
    "W0, W1 = np.meshgrid(w0_range, w1_range)\n",
    "\n",
    "Z = np.zeros_like(W0)\n",
    "\n",
    "if len(feature_indices_2) == 3:\n",
    "    bias_value = results_2['weights'][2, 0]\n",
    "    for i in range(W0.shape[0]):\n",
    "        for j in range(W0.shape[1]):\n",
    "            w_temp = np.array([[W0[i, j]], [W1[i, j]], [bias_value]])\n",
    "            Z[i, j] = compute_loss_for_weights(w_temp, X_2_weights, y)\n",
    "else:\n",
    "    for i in range(W0.shape[0]):\n",
    "        for j in range(W0.shape[1]):\n",
    "            w_temp = np.array([[W0[i, j]], [W1[i, j]]])\n",
    "            Z[i, j] = compute_loss_for_weights(w_temp, X_2_weights, y)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Vista 3D\n",
    "ax1 = fig.add_subplot(221, projection='3d')\n",
    "surface = ax1.plot_surface(W0, W1, Z, cmap='viridis', alpha=0.6, edgecolor='none', linewidth=0, antialiased=True)\n",
    "iterations = np.arange(len(results_2['weights_history']))\n",
    "scatter = ax1.scatter(results_2['weights_history'][:, 0], \n",
    "                      results_2['weights_history'][:, 1], \n",
    "                      results_2['loss_history'],\n",
    "                      c=iterations, \n",
    "                      cmap='hot', \n",
    "                      s=3,\n",
    "                      alpha=0.8)\n",
    "ax1.plot(results_2['weights_history'][:, 0], \n",
    "         results_2['weights_history'][:, 1], \n",
    "         results_2['loss_history'], \n",
    "         'r-', \n",
    "         alpha=0.5, \n",
    "         linewidth=1.5,\n",
    "         label='Trajetoria')\n",
    "ax1.scatter([results_2['weights_history'][0, 0]], \n",
    "            [results_2['weights_history'][0, 1]], \n",
    "            [results_2['loss_history'][0]], \n",
    "            c='lime', \n",
    "            s=200, \n",
    "            marker='o', \n",
    "            label='Inicio',\n",
    "            edgecolors='black',\n",
    "            linewidths=2)\n",
    "ax1.scatter([results_2['weights_history'][-1, 0]], \n",
    "            [results_2['weights_history'][-1, 1]], \n",
    "            [results_2['loss_history'][-1]], \n",
    "            c='red', \n",
    "            s=200, \n",
    "            marker='*', \n",
    "            label='Final',\n",
    "            edgecolors='black',\n",
    "            linewidths=2)\n",
    "ax1.set_xlabel(f'w_{top_2_indices[0]}', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel(f'w_{top_2_indices[1]}', fontsize=12, fontweight='bold')\n",
    "ax1.set_zlabel('Loss', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Trajetoria 3D - Versao 3', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.view_init(elev=25, azim=45)\n",
    "\n",
    "# Projecao 2D\n",
    "ax2 = fig.add_subplot(222)\n",
    "levels = 30\n",
    "contour = ax2.contour(W0, W1, Z, levels=levels, cmap='viridis', alpha=0.6, linewidths=0.5)\n",
    "ax2.clabel(contour, inline=True, fontsize=7, fmt='%.4f')\n",
    "contourf = ax2.contourf(W0, W1, Z, levels=levels, cmap='viridis', alpha=0.4)\n",
    "\n",
    "trajectory = ax2.plot(results_2['weights_history'][:, 0], \n",
    "                      results_2['weights_history'][:, 1], \n",
    "                      'r-', \n",
    "                      alpha=0.7, \n",
    "                      linewidth=2,\n",
    "                      label='Trajetoria')\n",
    "step = max(1, len(results_2['weights_history']) // 50)\n",
    "scatter2 = ax2.scatter(results_2['weights_history'][::step, 0], \n",
    "                       results_2['weights_history'][::step, 1], \n",
    "                       c=iterations[::step], \n",
    "                       cmap='hot', \n",
    "                       s=30, \n",
    "                       alpha=0.8,\n",
    "                       edgecolors='black',\n",
    "                       linewidths=0.5,\n",
    "                       zorder=5)\n",
    "ax2.scatter([results_2['weights_history'][0, 0]], \n",
    "            [results_2['weights_history'][0, 1]], \n",
    "            c='lime', \n",
    "            s=200, \n",
    "            marker='o', \n",
    "            label='Inicio', \n",
    "            edgecolors='black', \n",
    "            linewidths=2,\n",
    "            zorder=10)\n",
    "ax2.scatter([results_2['weights_history'][-1, 0]], \n",
    "            [results_2['weights_history'][-1, 1]], \n",
    "            c='red', \n",
    "            s=200, \n",
    "            marker='*', \n",
    "            label='Final', \n",
    "            edgecolors='black', \n",
    "            linewidths=2,\n",
    "            zorder=10)\n",
    "ax2.set_xlabel(f'w_{top_2_indices[0]}', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel(f'w_{top_2_indices[1]}', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Projecao 2D - Versao 3', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "plt.colorbar(contourf, ax=ax2, label='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nConfiguracoes: N_WEIGHTS = {N_WEIGHTS}\")\n",
    "print(f\"\\nPesos selecionados:\")\n",
    "print(f\"  - TOP {N_WEIGHTS}: {list(top_n_indices)}\")\n",
    "print(f\"  - TOP 2: {list(top_2_indices)}\")\n",
    "print(f\"\\nConclusao:\")\n",
    "print(f\"  A versao com {len(feature_indices_n) -1} pesos oferece:\")\n",
    "print(f\"    - {speedup_n:.2f}% speedup\")\n",
    "print(f\"    - {deg_n:.2f}% de degradacao na loss\")\n",
    "print(f\"  A versao com {len(feature_indices_2) -1} pesos oferece:\")\n",
    "print(f\"    - {speedup_2:.2f}% speedup\")\n",
    "print(f\"    - {deg_2:.2f}% de degradacao na loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
